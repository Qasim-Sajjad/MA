from huggingface_hub import login, InferenceClient
from dotenv import load_dotenv
import json
import os

load_dotenv(dotenv_path='.env')

#LYRICS BASED SENTIMENT ANALYSIS.

class LyricsExtractor:
    def __init__(self, model_name="mistralai/Mixtral-8x7B-Instruct-v0.1"):
        """
        Initializes the sentiment analyzer with a specified model.

        Args:
            model_name (str): Hugging Face model name for LLM. Defaults to "mistralai/Mixtral-8x7B-Instruct-v0.1".
        """ 
        token = os.getenv(key='hf_mixtral')

        if (token == None):
            raise ValueError("MIXTRAL LLM TOKEN DOES NOT EXIST, PLEASE CREATE A .ENV FILE AND PASTE token with name 'hf_mixtral'.")
        else:
            #Login to HuggingFace Hub.
            login(token=token,add_to_git_credential=True)

            # Using Mixtral , because it ranks great at chatbot arena, for generation of QA Pairs.
            repo_id = "mistralai/Mixtral-8x7B-Instruct-v0.1"

            self.llm_client = InferenceClient(
                model=repo_id,
                timeout=200,
            )


    def call_llm(self,
                 inference_client: InferenceClient,
                 prompt: str,
                 max_tokens:int):

        response = inference_client.post(
            json={
                "inputs": prompt,
                "parameters": {"max_new_tokens": max_tokens},
                "task": "text-generation",
            },
        )
        return json.loads(response.decode())[0]["generated_text"]


    def analyze_sentiment(self, lyrics_text, max_new_tokens=60):
        """
        Analyzes the sentiment of the provided lyrics.

        Args:
            lyrics_text (str): Lyrics text to analyze.
            max_new_tokens (int): Maximum number of tokens to generate.

        Returns:
            str: Sentiment analysis generated by the model.
        """

        # Create the prompt for sentiment analysis
        prompt = (
            f"Below are some song lyrics:\n\n{lyrics_text}\n\n"
            "Analyze the text above and describe the overall sentiment and mood of these lyrics in one short and concise sentence. Provide your response after the [RESULT] token.\n\n [RESULT]"
        )

        # Generate the result
        result_text = self.call_llm(self.llm_client, prompt, max_new_tokens)

        # Return the generated text
        return result_text